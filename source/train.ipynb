{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from typing import Tuple\n",
    "from types import SimpleNamespace\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loaders.example_data_loader import ExampleDatasetGenerator\n",
    "from models.models import JukeboxModel\n",
    "from models.preprocessing import AudioFeatureExtractor\n",
    "from utils.dirs import create_dirs\n",
    "from utils.config import process_config\n",
    "from utils.utils import get_args\n",
    "\n",
    "import datasets.canonne_duos.canonne_duos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "namespace(exp_name='Something', data=namespace(audio=namespace(time=namespace(size_win=1024, stride_win=256, rate_sample=48000), freq=namespace(freq_min=80, freq_max=10000, nb_mfcc=32), features=namespace(kind='descriptors', names=['freq_0', 'prob_freq', 'root_mean_square', 'zero_crossing_rate', 'spectral_flatness', 'spectral_centroid'])), annotations=namespace(size_kernel=3, sigma=1)), model=namespace(jukebox=namespace(nb_levels=2, nb_filters=8, nb_blocks_sample=[3, 5], size_kernel_sample=4, stride_sample=2, nb_blocks_res=[4, 2], size_kernel_res=3, rate_dilation_res=3, size_codebook=256, beta_codebook=0.99)), loss=namespace(), training=namespace(rate_learning=0.02, size_batch=8, nb_epochs=10), dataset=namespace(name='canonne_duos', validation_split=0.1, path=PosixPath('/data/anasynth_nonbp/thiel/tensorflow_datasets')), save=namespace(log=namespace(update_freq=1), checkpoint=namespace(max_to_keep=5, checkpoint_interval=2), path=namespace(log_dir='/data/anasynth_nonbp/thiel/saved_models/listening_tests/Something/log/', checkpoint_dir='/data/anasynth_nonbp/thiel/saved_models/listening_tests/Something/checkpoint/')), debug=namespace(enabled=True))\n"
     ]
    }
   ],
   "source": [
    "config_path = './configs/something_descriptors_config.json'\n",
    "save_root_path = '/data/anasynth_nonbp/thiel/saved_models/listening_tests/'\n",
    "dataset_path = '/data/anasynth_nonbp/thiel/tensorflow_datasets/'\n",
    "# capture the config path from the run arguments\n",
    "# then process the json configuration file\n",
    "args = SimpleNamespace(\n",
    "    config=config_path,\n",
    "    save_root=save_root_path,\n",
    "    dataset=dataset_path\n",
    ")\n",
    "config = process_config(args)\n",
    "\n",
    "# create the experiments dirs\n",
    "create_dirs([config.save.path.log_dir,\n",
    "            config.save.path.checkpoint_dir])\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "no gpu manager available - will use all available GPUs\n"
     ]
    }
   ],
   "source": [
    "import manage_gpus as gpl\n",
    "try:\n",
    "    id_gpu_locked = gpl.get_gpu_lock(soft=True)\n",
    "    comp_device = f\"/gpu:{id_gpu_locked}\"\n",
    "    # os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\"\n",
    "except gpl.NoGpuManager:\n",
    "    print(\"no gpu manager available - will use all available GPUs\", file=sys.stderr)\n",
    "except gpl.NoGpuAvailable:\n",
    "    # there is no GPU available for locking, continue with CPU\n",
    "    comp_device = \"/cpu:0\" \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\"\n",
    "\n",
    "if \"CUDA_VISIBLE_DEVICES\" in os.environ and len(os.environ[\"CUDA_VISIBLE_DEVICES\"]) > 0:\n",
    "    devices = tf.config.list_physical_devices('GPU')\n",
    "    print(len(devices))\n",
    "    tf.config.experimental.set_memory_growth(device=devices[0], enable=True)\n",
    "else:\n",
    "    comp_device = \"/cpu:0\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParseError",
     "evalue": "Failed to construct dataset canonne_duos: Message type \"tensorflow_datasets.DatasetInfo\" has no field named \"fileFormat\" at \"DatasetInfo\".\n Available Fields(except extensions): \"['name', 'description', 'version', 'configName', 'configDescription', 'citation', 'sizeInBytes', 'downloadSize', 'location', 'downloadChecksums', 'schema', 'splits', 'supervisedKeys', 'redistributionInfo', 'moduleName', 'disableShuffling']\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParseError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/google/protobuf/json_format.py:544\u001b[0m, in \u001b[0;36m_Parser._ConvertFieldValuePair\u001b[0;34m(self, js, message, path)\u001b[0m\n\u001b[1;32m    <a href='file:///data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/google/protobuf/json_format.py?line=542'>543</a>\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m--> <a href='file:///data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/google/protobuf/json_format.py?line=543'>544</a>\u001b[0m   \u001b[39mraise\u001b[39;00m ParseError(\n\u001b[1;32m    <a href='file:///data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/google/protobuf/json_format.py?line=544'>545</a>\u001b[0m       (\u001b[39m'\u001b[39m\u001b[39mMessage type \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m has no field named \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m at \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m    <a href='file:///data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/google/protobuf/json_format.py?line=545'>546</a>\u001b[0m        \u001b[39m'\u001b[39m\u001b[39m Available Fields(except extensions): \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{3}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    <a href='file:///data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/google/protobuf/json_format.py?line=546'>547</a>\u001b[0m            message_descriptor\u001b[39m.\u001b[39mfull_name, name, path,\n\u001b[1;32m    <a href='file:///data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/google/protobuf/json_format.py?line=547'>548</a>\u001b[0m            [f\u001b[39m.\u001b[39mjson_name \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m message_descriptor\u001b[39m.\u001b[39mfields]))\n\u001b[1;32m    <a href='file:///data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/google/protobuf/json_format.py?line=548'>549</a>\u001b[0m \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m names:\n",
      "\u001b[0;31mParseError\u001b[0m: Message type \"tensorflow_datasets.DatasetInfo\" has no field named \"fileFormat\" at \"DatasetInfo\".\n Available Fields(except extensions): \"['name', 'description', 'version', 'configName', 'configDescription', 'citation', 'sizeInBytes', 'downloadSize', 'location', 'downloadChecksums', 'schema', 'splits', 'supervisedKeys', 'redistributionInfo', 'moduleName', 'disableShuffling']\"",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mParseError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/u/atiam/2021-2022/thiel/repositories/listening_tests/source/train.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bbonsho/u/atiam/2021-2022/thiel/repositories/listening_tests/source/train.ipynb#ch0000004vscode-remote?line=0'>1</a>\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mdevice(comp_device):\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bbonsho/u/atiam/2021-2022/thiel/repositories/listening_tests/source/train.ipynb#ch0000004vscode-remote?line=2'>3</a>\u001b[0m     ds_train, ds_val \u001b[39m=\u001b[39m tfds\u001b[39m.\u001b[39;49mload(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bbonsho/u/atiam/2021-2022/thiel/repositories/listening_tests/source/train.ipynb#ch0000004vscode-remote?line=3'>4</a>\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39mcanonne_duos\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bbonsho/u/atiam/2021-2022/thiel/repositories/listening_tests/source/train.ipynb#ch0000004vscode-remote?line=4'>5</a>\u001b[0m         split\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mtrain[90\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m:]\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mtrain[:10\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m]\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bbonsho/u/atiam/2021-2022/thiel/repositories/listening_tests/source/train.ipynb#ch0000004vscode-remote?line=5'>6</a>\u001b[0m         data_dir\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mdataset\u001b[39m.\u001b[39;49mpath,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bbonsho/u/atiam/2021-2022/thiel/repositories/listening_tests/source/train.ipynb#ch0000004vscode-remote?line=6'>7</a>\u001b[0m         download\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bbonsho/u/atiam/2021-2022/thiel/repositories/listening_tests/source/train.ipynb#ch0000004vscode-remote?line=7'>8</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbonsho/u/atiam/2021-2022/thiel/repositories/listening_tests/source/train.ipynb#ch0000004vscode-remote?line=9'>10</a>\u001b[0m     shape_preprocessed \u001b[39m=\u001b[39m ds_train\u001b[39m.\u001b[39melement_spec[\u001b[39m'\u001b[39m\u001b[39maudio\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mshape\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbonsho/u/atiam/2021-2022/thiel/repositories/listening_tests/source/train.ipynb#ch0000004vscode-remote?line=11'>12</a>\u001b[0m     feature_extractor \u001b[39m=\u001b[39m AudioFeatureExtractor\u001b[39m.\u001b[39mmake(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbonsho/u/atiam/2021-2022/thiel/repositories/listening_tests/source/train.ipynb#ch0000004vscode-remote?line=12'>13</a>\u001b[0m         kind_feature\u001b[39m=\u001b[39mconfig\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39maudio\u001b[39m.\u001b[39mfeatures\u001b[39m.\u001b[39mkind,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbonsho/u/atiam/2021-2022/thiel/repositories/listening_tests/source/train.ipynb#ch0000004vscode-remote?line=13'>14</a>\u001b[0m         name_features\u001b[39m=\u001b[39mconfig\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39maudio\u001b[39m.\u001b[39mfeatures\u001b[39m.\u001b[39mnames,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbonsho/u/atiam/2021-2022/thiel/repositories/listening_tests/source/train.ipynb#ch0000004vscode-remote?line=19'>20</a>\u001b[0m         nb_mfcc\u001b[39m=\u001b[39mconfig\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39maudio\u001b[39m.\u001b[39mfreq\u001b[39m.\u001b[39mnb_mfcc\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbonsho/u/atiam/2021-2022/thiel/repositories/listening_tests/source/train.ipynb#ch0000004vscode-remote?line=20'>21</a>\u001b[0m     )\n",
      "File \u001b[0;32m/data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/tensorflow_datasets/core/load.py:330\u001b[0m, in \u001b[0;36mload\u001b[0;34m(name, split, data_dir, batch_size, shuffle_files, download, as_supervised, decoders, read_config, with_info, builder_kwargs, download_and_prepare_kwargs, as_dataset_kwargs, try_gcs)\u001b[0m\n\u001b[1;32m    <a href='file:///data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/tensorflow_datasets/core/load.py?line=326'>327</a>\u001b[0m \u001b[39mif\u001b[39;00m builder_kwargs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/tensorflow_datasets/core/load.py?line=327'>328</a>\u001b[0m   builder_kwargs \u001b[39m=\u001b[39m {}\n\u001b[0;32m--> <a href='file:///data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/tensorflow_datasets/core/load.py?line=329'>330</a>\u001b[0m dbuilder \u001b[39m=\u001b[39m builder(name, data_dir\u001b[39m=\u001b[39;49mdata_dir, try_gcs\u001b[39m=\u001b[39;49mtry_gcs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mbuilder_kwargs)\n\u001b[1;32m    <a href='file:///data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/tensorflow_datasets/core/load.py?line=330'>331</a>\u001b[0m \u001b[39mif\u001b[39;00m download:\n\u001b[1;32m    <a href='file:///data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/tensorflow_datasets/core/load.py?line=331'>332</a>\u001b[0m   download_and_prepare_kwargs \u001b[39m=\u001b[39m download_and_prepare_kwargs \u001b[39mor\u001b[39;00m {}\n",
      "File \u001b[0;32m/data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/tensorflow_datasets/core/load.py:177\u001b[0m, in \u001b[0;36mbuilder\u001b[0;34m(name, try_gcs, **builder_kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/tensorflow_datasets/core/load.py?line=174'>175</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m:\n\u001b[1;32m    <a href='file:///data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/tensorflow_datasets/core/load.py?line=175'>176</a>\u001b[0m   \u001b[39mwith\u001b[39;00m py_utils\u001b[39m.\u001b[39mtry_reraise(prefix\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mFailed to construct dataset \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m--> <a href='file:///data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/tensorflow_datasets/core/load.py?line=176'>177</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mbuilder_kwargs)  \u001b[39m# pytype: disable=not-instantiable\u001b[39;00m\n\u001b[1;32m    <a href='file:///data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/tensorflow_datasets/core/load.py?line=178'>179</a>\u001b[0m \u001b[39m# If neither the code nor the files are found, raise DatasetNotFoundError\u001b[39;00m\n\u001b[1;32m    <a href='file:///data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/tensorflow_datasets/core/load.py?line=179'>180</a>\u001b[0m \u001b[39mraise\u001b[39;00m not_found_error\n",
      "File \u001b[0;32m/data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/tensorflow_datasets/core/dataset_builder.py:923\u001b[0m, in \u001b[0;36mFileReaderBuilder.__init__\u001b[0;34m(self, file_format, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/tensorflow_datasets/core/dataset_builder.py?line=906'>907</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m    <a href='file:///data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/tensorflow_datasets/core/dataset_builder.py?line=907'>908</a>\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    <a href='file:///data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/tensorflow_datasets/core/dataset_builder.py?line=908'>909</a>\u001b[0m     \u001b[39m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/tensorflow_datasets/core/dataset_builder.py?line=911'>912</a>\u001b[0m         file_adapters\u001b[39m.\u001b[39mFileFormat] \u001b[39m=\u001b[39m file_adapters\u001b[39m.\u001b[39mDEFAULT_FILE_FORMAT,\n\u001b[1;32m    <a href='file:///data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/tensorflow_datasets/core/dataset_builder.py?line=912'>913</a>\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any):\n\u001b[1;32m    <a href='file:///data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/tensorflow_datasets/core/dataset_builder.py?line=913'>914</a>\u001b[0m   \u001b[39m\"\"\"Initializes an instance of FileReaderBuilder.\u001b[39;00m\n\u001b[1;32m    <a href='file:///data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/tensorflow_datasets/core/dataset_builder.py?line=914'>915</a>\u001b[0m \n\u001b[1;32m    <a href='file:///data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/tensorflow_datasets/core/dataset_builder.py?line=915'>916</a>\u001b[0m \u001b[39m  Callers must pass arguments as keyword arguments.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/tensorflow_datasets/core/dataset_builder.py?line=920'>921</a>\u001b[0m \u001b[39m    **kwargs: Arguments passed to `DatasetBuilder`.\u001b[39;00m\n\u001b[1;32m    <a href='file:///data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/tensorflow_datasets/core/dataset_builder.py?line=921'>922</a>\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/tensorflow_datasets/core/dataset_builder.py?line=922'>923</a>\u001b[0m   \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/tensorflow_datasets/core/dataset_builder.py?line=923'>924</a>\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    <a href='file:///data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/tensorflow_datasets/core/dataset_builder.py?line=924'>925</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_file_format \u001b[39m=\u001b[39m file_adapters\u001b[39m.\u001b[39mFileFormat(file_format)\n",
      "File \u001b[0;32m/data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/tensorflow_datasets/core/dataset_builder.py:182\u001b[0m, in \u001b[0;36mDatasetBuilder.__init__\u001b[0;34m(self, data_dir, config, version)\u001b[0m\n\u001b[1;32m    <a href='file:///data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/tensorflow_datasets/core/dataset_builder.py?line=179'>180</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_dir_root, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_dir \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_data_dir(data_dir)\n\u001b[1;32m    <a href='file:///data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/tensorflow_datasets/core/dataset_builder.py?line=180'>181</a>\u001b[0m \u001b[39mif\u001b[39;00m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39mexists(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_dir):\n\u001b[0;32m--> <a href='file:///data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/tensorflow_datasets/core/dataset_builder.py?line=181'>182</a>\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minfo\u001b[39m.\u001b[39;49mread_from_directory(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_dir)\n\u001b[1;32m    <a href='file:///data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/tensorflow_datasets/core/dataset_builder.py?line=182'>183</a>\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# Use the code version (do not restore data)\u001b[39;00m\n\u001b[1;32m    <a href='file:///data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/tensorflow_datasets/core/dataset_builder.py?line=183'>184</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39minitialize_from_bucket()\n",
      "File \u001b[0;32m/data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/tensorflow_datasets/core/dataset_info.py:377\u001b[0m, in \u001b[0;36mDatasetInfo.read_from_directory\u001b[0;34m(self, dataset_info_dir)\u001b[0m\n\u001b[1;32m    <a href='file:///data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/tensorflow_datasets/core/dataset_info.py?line=368'>369</a>\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\n\u001b[1;32m    <a href='file:///data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/tensorflow_datasets/core/dataset_info.py?line=369'>370</a>\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mTry to load `DatasetInfo` from a directory which does not exist or \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/tensorflow_datasets/core/dataset_info.py?line=370'>371</a>\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mdoes not contain `dataset_info.json`. Please delete the directory \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/tensorflow_datasets/core/dataset_info.py?line=371'>372</a>\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m`\u001b[39m\u001b[39m{\u001b[39;00mdataset_info_dir\u001b[39m}\u001b[39;00m\u001b[39m`  if you are trying to re-generate the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/tensorflow_datasets/core/dataset_info.py?line=372'>373</a>\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mdataset.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/tensorflow_datasets/core/dataset_info.py?line=373'>374</a>\u001b[0m   )\n\u001b[1;32m    <a href='file:///data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/tensorflow_datasets/core/dataset_info.py?line=375'>376</a>\u001b[0m \u001b[39m# Load the metadata from disk\u001b[39;00m\n\u001b[0;32m--> <a href='file:///data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/tensorflow_datasets/core/dataset_info.py?line=376'>377</a>\u001b[0m parsed_proto \u001b[39m=\u001b[39m read_from_json(json_filename)\n\u001b[1;32m    <a href='file:///data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/tensorflow_datasets/core/dataset_info.py?line=378'>379</a>\u001b[0m \u001b[39m# Update splits\u001b[39;00m\n\u001b[1;32m    <a href='file:///data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/tensorflow_datasets/core/dataset_info.py?line=379'>380</a>\u001b[0m split_dict \u001b[39m=\u001b[39m splits_lib\u001b[39m.\u001b[39mSplitDict\u001b[39m.\u001b[39mfrom_proto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname, parsed_proto\u001b[39m.\u001b[39msplits)\n",
      "File \u001b[0;32m/data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/tensorflow_datasets/core/dataset_info.py:558\u001b[0m, in \u001b[0;36mread_from_json\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    <a href='file:///data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/tensorflow_datasets/core/dataset_info.py?line=555'>556</a>\u001b[0m json_str \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39mas_path(path)\u001b[39m.\u001b[39mread_text()\n\u001b[1;32m    <a href='file:///data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/tensorflow_datasets/core/dataset_info.py?line=556'>557</a>\u001b[0m \u001b[39m# Parse it back into a proto.\u001b[39;00m\n\u001b[0;32m--> <a href='file:///data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/tensorflow_datasets/core/dataset_info.py?line=557'>558</a>\u001b[0m parsed_proto \u001b[39m=\u001b[39m json_format\u001b[39m.\u001b[39;49mParse(json_str, dataset_info_pb2\u001b[39m.\u001b[39;49mDatasetInfo())\n\u001b[1;32m    <a href='file:///data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/tensorflow_datasets/core/dataset_info.py?line=558'>559</a>\u001b[0m \u001b[39mreturn\u001b[39;00m parsed_proto\n",
      "File \u001b[0;32m/data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/google/protobuf/json_format.py:436\u001b[0m, in \u001b[0;36mParse\u001b[0;34m(text, message, ignore_unknown_fields, descriptor_pool, max_recursion_depth)\u001b[0m\n\u001b[1;32m    <a href='file:///data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/google/protobuf/json_format.py?line=433'>434</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    <a href='file:///data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/google/protobuf/json_format.py?line=434'>435</a>\u001b[0m   \u001b[39mraise\u001b[39;00m ParseError(\u001b[39m'\u001b[39m\u001b[39mFailed to load JSON: \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mstr\u001b[39m(e)))\n\u001b[0;32m--> <a href='file:///data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/google/protobuf/json_format.py?line=435'>436</a>\u001b[0m \u001b[39mreturn\u001b[39;00m ParseDict(js, message, ignore_unknown_fields, descriptor_pool,\n\u001b[1;32m    <a href='file:///data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/google/protobuf/json_format.py?line=436'>437</a>\u001b[0m                  max_recursion_depth)\n",
      "File \u001b[0;32m/data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/google/protobuf/json_format.py:461\u001b[0m, in \u001b[0;36mParseDict\u001b[0;34m(js_dict, message, ignore_unknown_fields, descriptor_pool, max_recursion_depth)\u001b[0m\n\u001b[1;32m    <a href='file:///data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/google/protobuf/json_format.py?line=444'>445</a>\u001b[0m \u001b[39m\"\"\"Parses a JSON dictionary representation into a message.\u001b[39;00m\n\u001b[1;32m    <a href='file:///data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/google/protobuf/json_format.py?line=445'>446</a>\u001b[0m \n\u001b[1;32m    <a href='file:///data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/google/protobuf/json_format.py?line=446'>447</a>\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/google/protobuf/json_format.py?line=457'>458</a>\u001b[0m \u001b[39m  The same message passed as argument.\u001b[39;00m\n\u001b[1;32m    <a href='file:///data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/google/protobuf/json_format.py?line=458'>459</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/google/protobuf/json_format.py?line=459'>460</a>\u001b[0m parser \u001b[39m=\u001b[39m _Parser(ignore_unknown_fields, descriptor_pool, max_recursion_depth)\n\u001b[0;32m--> <a href='file:///data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/google/protobuf/json_format.py?line=460'>461</a>\u001b[0m parser\u001b[39m.\u001b[39;49mConvertMessage(js_dict, message, \u001b[39m'\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m    <a href='file:///data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/google/protobuf/json_format.py?line=461'>462</a>\u001b[0m \u001b[39mreturn\u001b[39;00m message\n",
      "File \u001b[0;32m/data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/google/protobuf/json_format.py:502\u001b[0m, in \u001b[0;36m_Parser.ConvertMessage\u001b[0;34m(self, value, message, path)\u001b[0m\n\u001b[1;32m    <a href='file:///data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/google/protobuf/json_format.py?line=499'>500</a>\u001b[0m   methodcaller(_WKTJSONMETHODS[full_name][\u001b[39m1\u001b[39m], value, message, path)(\u001b[39mself\u001b[39m)\n\u001b[1;32m    <a href='file:///data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/google/protobuf/json_format.py?line=500'>501</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/google/protobuf/json_format.py?line=501'>502</a>\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_ConvertFieldValuePair(value, message, path)\n\u001b[1;32m    <a href='file:///data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/google/protobuf/json_format.py?line=502'>503</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrecursion_depth \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m/data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/google/protobuf/json_format.py:629\u001b[0m, in \u001b[0;36m_Parser._ConvertFieldValuePair\u001b[0;34m(self, js, message, path)\u001b[0m\n\u001b[1;32m    <a href='file:///data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/google/protobuf/json_format.py?line=626'>627</a>\u001b[0m     \u001b[39mraise\u001b[39;00m ParseError(\u001b[39m'\u001b[39m\u001b[39mFailed to parse \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m field: \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(name, e))\n\u001b[1;32m    <a href='file:///data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/google/protobuf/json_format.py?line=627'>628</a>\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/google/protobuf/json_format.py?line=628'>629</a>\u001b[0m     \u001b[39mraise\u001b[39;00m ParseError(\u001b[39mstr\u001b[39m(e))\n\u001b[1;32m    <a href='file:///data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/google/protobuf/json_format.py?line=629'>630</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    <a href='file:///data/anasynth_nonbp/anaconda3/envs/tf2.8/lib/python3.9/site-packages/google/protobuf/json_format.py?line=630'>631</a>\u001b[0m   \u001b[39mraise\u001b[39;00m ParseError(\u001b[39m'\u001b[39m\u001b[39mFailed to parse \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m field: \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(name, e))\n",
      "\u001b[0;31mParseError\u001b[0m: Failed to construct dataset canonne_duos: Message type \"tensorflow_datasets.DatasetInfo\" has no field named \"fileFormat\" at \"DatasetInfo\".\n Available Fields(except extensions): \"['name', 'description', 'version', 'configName', 'configDescription', 'citation', 'sizeInBytes', 'downloadSize', 'location', 'downloadChecksums', 'schema', 'splits', 'supervisedKeys', 'redistributionInfo', 'moduleName', 'disableShuffling']\""
     ]
    }
   ],
   "source": [
    "with tf.device(comp_device):\n",
    "\n",
    "    ds_train, ds_val = tfds.load(\n",
    "        'canonne_duos',\n",
    "        split=['train[90%:]', 'train[:10%]'],\n",
    "        data_dir=config.dataset.path,\n",
    "        download=False\n",
    "    )\n",
    "    \n",
    "    shape_preprocessed = ds_train.element_spec['audio'].shape\n",
    "\n",
    "    feature_extractor = AudioFeatureExtractor.make(\n",
    "        kind_feature=config.data.audio.features.kind,\n",
    "        name_features=config.data.audio.features.names,\n",
    "        rate_sample=config.data.audio.time.rate_sample,\n",
    "        size_win=config.data.audio.time.size_win,\n",
    "        stride_win=config.data.audio.time.stride_win,\n",
    "        freq_min=config.data.audio.freq.freq_min,\n",
    "        freq_max=config.data.audio.freq.freq_max,\n",
    "        nb_mfcc=config.data.audio.freq.nb_mfcc\n",
    "    )\n",
    "\n",
    "    @tf.function\n",
    "    def _preprocess(inputs: dict) -> Tuple[tf.Tensor, tf.Tensor]:\n",
    "        x_audio = inputs['audio']\n",
    "        x_features = feature_extractor(x_audio)\n",
    "        x = x_features\n",
    "        y = x\n",
    "        return x, y\n",
    "    \n",
    "    # for now, process left and right channel separately\n",
    "    # stereo example as two mono examples -> unbatch then batch again.\n",
    "    ds_train = ds_train.map(_preprocess) \\\n",
    "        .unbatch() \\\n",
    "        .shuffle(4) \\\n",
    "        .batch(config.training.size_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d36812dbbf1540ce8d20e33fac882da9e3eee4da48c935ef3fd1f2aaf16696a2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit ('tf2.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
